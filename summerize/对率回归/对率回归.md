# 对率回归中的概率含义与公式说明

在对率回归（Logistic Regression）中，我们用概率来描述样本属于某一类别的可能性。

## p1 和 p0 的含义
- $p_1(\hat{x}_i; \beta) = p(y=1|\hat{x}_i; \beta)$：表示在给定特征 $\hat{x}_i$ 和参数 $\beta$ 的情况下，样本属于“正类”（即 $y=1$）的概率。
- $p_0(\hat{x}_i; \beta) = p(y=0|\hat{x}_i; \beta)$：表示在同样条件下，样本属于“负类”（即 $y=0$）的概率。

具体公式：
$$
p_1(\hat{x}_i; \beta) = \frac{e^{\beta^T \hat{x}_i}}{1 + e^{\beta^T \hat{x}_i}}
$$
$$
p_0(\hat{x}_i; \beta) = 1 - p_1(\hat{x}_i; \beta) = \frac{1}{1 + e^{\beta^T \hat{x}_i}}
$$

## 什么情况下是真正类
- 当 $y_i=1$ 时，样本的真实类别是“正类”，此时 $p_1$ 就是模型对该样本预测为正类的概率。
- 当 $y_i=0$ 时，样本的真实类别是“负类”，此时 $p_0$ 就是模型对该样本预测为负类的概率。

## 似然函数与最大化
对率回归通过最大化所有样本的似然函数（即所有样本被正确分类的概率之积）来估计参数。

联合概率可写为：
$$
p(y_i|x_i, w, b) = y_i p_1(\hat{x}_i; \beta) + (1-y_i) p_0(\hat{x}_i; \beta)
$$

这样，无论 $y_i$ 是 0 还是 1，都能用一个公式统一表示。

## 似然函数最大化与梯度下降解法

在对率回归中，我们通过最大化似然函数来估计参数 $\beta$。似然函数为所有样本联合概率的乘积：
$$
L(\beta) = \prod_{i=1}^m p(y_i|x_i, \beta)
$$

通常取对数似然，便于计算：
$$
\ell(\beta) = \sum_{i=1}^m \ln p(y_i|x_i, \beta)
$$

将联合概率公式代入：
$$
\ell(\beta) = \sum_{i=1}^m \left[ y_i \ln p_1(\hat{x}_i; \beta) + (1-y_i) \ln p_0(\hat{x}_i; \beta) \right]
$$

进一步代入 $p_1$ 和 $p_0$ 的表达式，得到：
$$
\ell(\beta) = \sum_{i=1}^m \left[ y_i (\beta^T \hat{x}_i) - \ln(1 + e^{\beta^T \hat{x}_i}) \right]
$$

### 梯度下降法求解参数

由于对数似然函数是凸函数，无法直接解析求解最大值，常用梯度下降法进行数值优化。

1. 计算对数似然的梯度：
   $$
   \nabla_{\beta} \ell(\beta) = \sum_{i=1}^m \left[ y_i - \sigma(\beta^T \hat{x}_i) \right] \hat{x}_i
   $$
   其中 $\sigma(z) = \frac{1}{1 + e^{-z}}$ 是 sigmoid 函数。

2. 梯度上升（最大化对数似然）：
   $$
   \beta \leftarrow \beta + \eta \nabla_{\beta} \ell(\beta)
   $$
   其中 $\eta$ 为学习率。

3. 或者最小化负对数似然（损失函数），用梯度下降：
   $$
   \beta \leftarrow \beta - \eta \nabla_{\beta} [-\ell(\beta)]
   $$

4. 重复迭代，直到收敛。

---

这样，通过最大化似然函数并使用梯度下降法，可以高效地估计对率回归模型的参数。

---

本节内容帮助理解对率回归中概率的含义及其在分类任务中的作用。